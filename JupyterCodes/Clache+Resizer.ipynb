{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6faa1f90-50c5-4926-9f7d-cefe1749b20a",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf2d65c-6e06-441a-b599-4ae9b0cb28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9add02-8fcf-46c1-bea8-301a1602a20e",
   "metadata": {},
   "source": [
    "# This code resize by skipping pixels in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b15ed3a4-e962-4a7e-b077-0124e3394d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 30/30 [00:01<00:00, 18.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1 \n",
    "class ImageResizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [cv2.resize(img, (self.width, self.height), interpolation=cv2.INTER_AREA) for img in X]\n",
    "\n",
    "\n",
    "# 2\n",
    "class CLAHEEnhancer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(16, 16)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "        return [clahe.apply(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)) for img in X]\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif'))\n",
    "\n",
    "def preprocess_images(image_folder, output_dir):\n",
    "    logging.basicConfig(filename='image_processing.log', level=logging.INFO)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    processed_dir = os.path.join(output_dir, 'processed_images(Clache+size)')\n",
    "    if not os.path.exists(processed_dir):\n",
    "        os.makedirs(processed_dir)\n",
    "    \n",
    "    # Create the pipeline\n",
    "    pipeline = make_pipeline(\n",
    "        ImageResizer(width=1935, height=1024),\n",
    "        CLAHEEnhancer(clip_limit=2.0, tile_grid_size=(16, 16))\n",
    "    )\n",
    "    \n",
    "    # Get a list of image files in the folder\n",
    "    image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder) if is_image_file(file)]\n",
    "    \n",
    "    for image_path in tqdm(image_files, desc=\"Processing images\"):\n",
    "        try:\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Image is None: {image_path}\")\n",
    "            \n",
    "            # Apply the pipeline\n",
    "            processed_img = pipeline.transform([img])[0]\n",
    "            \n",
    "            output_path = os.path.join(processed_dir, os.path.basename(image_path))\n",
    "            cv2.imwrite(output_path, processed_img)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing image {image_path}: {str(e)}\")\n",
    "\n",
    "# Folder containing your X-ray images (adjust this path)\n",
    "image_folder_path = r\"C:\\Users\\hp\\Desktop\\hepsi\\ONCE\\once-27\"\n",
    "# Directory where you want to save processed images\n",
    "processed_images_dir = r\"C:\\Users\\hp\\Desktop\\hepsi\\ONCE\\once-27-27\"\n",
    "# Call the function with the image folder path and processed directory\n",
    "preprocess_images(image_folder_path, processed_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a43840-81df-4445-9974-a00efb178333",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Image individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df478d29-47aa-4357-b174-9a7ee574415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: C:\\Users\\hp\\Desktop\\hepsi\\gümülü\\gumulu-1\\ABDULKARIM_ANADANI_jpg_ca93bbbd-5f1a-47c1-b087-72017a42fa11.jpg\n",
      "Image processing failed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class ImageResizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [cv2.resize(img, (self.width, self.height), interpolation=cv2.INTER_AREA) for img in X]\n",
    "\n",
    "class CLAHEEnhancer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, clip_limit=2.0, tile_grid_size=(16, 16)):\n",
    "        self.clip_limit = clip_limit\n",
    "        self.tile_grid_size = tile_grid_size\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "        return [clahe.apply(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)) for img in X]\n",
    "\n",
    "def process_image(image_path, output_dir):\n",
    "    try:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image: {image_path}\")\n",
    "            return False\n",
    "\n",
    "        pipeline = make_pipeline(\n",
    "            ImageResizer(width=1935, height=1024),\n",
    "            CLAHEEnhancer(clip_limit=2.0, tile_grid_size=(16, 16))\n",
    "        )\n",
    "\n",
    "        processed_img = pipeline.transform([img])[0]\n",
    "        \n",
    "        output_filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        cv2.imwrite(output_path, processed_img)\n",
    "        print(f\"Processed and saved: {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Specify the input image path here\n",
    "    input_path = r\"C:\\Users\\hp\\Desktop\\hepsi\\gümülü\\gumulu-1\\ABDULKARIM_ANADANI_jpg_ca93bbbd-5f1a-47c1-b087-72017a42fa11.jpg\"\n",
    "    \n",
    "    # Specify the output directory here\n",
    "    output_dir = r\"C:\\Users\\hp\\Desktop\\hepsi\\gümülü\\gumulu-1-1\\ABDULKARIM_ANADANI_jpg_ca93bbbd-5f1a-47c1-b087-72017a42fa11.jpg\"\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    success = process_image(input_path, output_dir)\n",
    "    if success:\n",
    "        print(\"Image processing completed successfully.\")\n",
    "    else:\n",
    "        print(\"Image processing failed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d97c0-53c6-47fc-b0c2-7bbb833aea52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1 is the resizer\n",
    "# 2 is the CLACHE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae9ed9-fb54-4e1d-8529-2129c6873ea5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# This Code resize by edges around the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d4a49f1-c197-4ef4-8f99-877609176140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import logging\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# class ImageCropper(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, width, height):\n",
    "#         \"\"\"\n",
    "#         Initialize the ImageCropper with the desired width and height.\n",
    "#         \"\"\"\n",
    "#         self.width = width\n",
    "#         self.height = height\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         \"\"\"\n",
    "#         Crop images to the specified width and height, keeping the center part.\n",
    "#         If the image is smaller than the target size, resize it first.\n",
    "#         \"\"\"\n",
    "#         cropped_images = []\n",
    "#         for img in X:\n",
    "#             if img.shape[1] < self.width or img.shape[0] < self.height:\n",
    "#                 # Resize the image to the minimum required dimensions\n",
    "#                 img = cv2.resize(img, (max(self.width, img.shape[1]), max(self.height, img.shape[0])), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "#             center_x, center_y = img.shape[1] // 2, img.shape[0] // 2\n",
    "#             half_width, half_height = self.width // 2, self.height // 2\n",
    "#             cropped_img = img[center_y - half_height:center_y + half_height, center_x - half_width:center_x + half_width]\n",
    "#             cropped_images.append(cropped_img)\n",
    "#         return cropped_images\n",
    "\n",
    "\n",
    "# class CLAHEEnhancer(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, clip_limit=2.0, tile_grid_size=(16, 16)):\n",
    "#         \"\"\"\n",
    "#         Initialize the CLAHEEnhancer with the desired clip limit and tile grid size.\n",
    "#         \"\"\"\n",
    "#         self.clip_limit = clip_limit\n",
    "#         self.tile_grid_size = tile_grid_size\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         \"\"\"\n",
    "#         Apply CLAHE to enhance the contrast of images.\n",
    "#         \"\"\"\n",
    "#         clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "#         return [clahe.apply(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)) for img in X]\n",
    "\n",
    "# def preprocess_images(image_folder, output_dir):\n",
    "#     \"\"\"\n",
    "#     Preprocess images by cropping and applying CLAHE, then save the processed images.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "#     processed_dir = os.path.join(output_dir, 'processed_images(Clache+size)')\n",
    "#     if not os.path.exists(processed_dir):\n",
    "#         os.makedirs(processed_dir)\n",
    "    \n",
    "#     # Create the pipeline\n",
    "#     pipeline = make_pipeline(\n",
    "#         ImageCropper(width=1930, height=1000),\n",
    "#         CLAHEEnhancer(clip_limit=2.0, tile_grid_size=(16, 16))\n",
    "#     )\n",
    "    \n",
    "#     # Get a list of image files in the folder\n",
    "#     image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder)]\n",
    "    \n",
    "#     for image_path in image_files:\n",
    "#         try:\n",
    "#             img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "#             if img is not None:\n",
    "#                 # Apply the pipeline\n",
    "#                 processed_img = pipeline.transform([img])[0]\n",
    "                \n",
    "#                 output_path = os.path.join(processed_dir, os.path.basename(image_path))\n",
    "#                 cv2.imwrite(output_path, processed_img)\n",
    "#                 logging.info(f\"Processed and saved image: {output_path}\")\n",
    "#             else:\n",
    "#                 logging.error(f\"Failed to load image: {image_path}\")\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "# # Folder containing your X-ray images (adjust this path)\n",
    "# image_folder_path = r\"C:\\Users\\hp\\Desktop\\2914---1470\"\n",
    "# # Directory where you want to save processed images\n",
    "# processed_images_dir = r\"C:\\Users\\hp\\Desktop\\ProcessedImages\"\n",
    "\n",
    "# # Call the function with the image folder path and processed directory\n",
    "# preprocess_images(image_folder_path, processed_images_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11ddd6-e8e7-4299-984e-d5d91e48535a",
   "metadata": {},
   "source": [
    "# Eggy shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "016ce1fb-d8ff-40d2-a5e6-3023f443ce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 13:05:20,935 - INFO - Processed and saved image: C:\\Users\\hp\\Desktop\\ProcessedImages\\processed_images(Clache+size)\\000000021972_NESE OZMEN_Panorama_20170627134309.jpg\n",
      "2024-08-18 13:05:20,978 - INFO - Processed and saved image: C:\\Users\\hp\\Desktop\\ProcessedImages\\processed_images(Clache+size)\\000000021977_ABDULKADIR SAGCAN_Panorama_20170627163926.jpg\n",
      "2024-08-18 13:05:21,042 - INFO - Processed and saved image: C:\\Users\\hp\\Desktop\\ProcessedImages\\processed_images(Clache+size)\\0000005045_AYSE HEKIMOGLU_Panorama_20140730133721.jpg\n",
      "2024-08-18 13:05:21,093 - INFO - Processed and saved image: C:\\Users\\hp\\Desktop\\ProcessedImages\\processed_images(Clache+size)\\1.3.6.1.4.1.25403.193662124755707.11904.20240112140657.136.jpg\n",
      "2024-08-18 13:05:21,143 - INFO - Processed and saved image: C:\\Users\\hp\\Desktop\\ProcessedImages\\processed_images(Clache+size)\\1.3.6.1.4.1.25403.193662124755707.1340.20240320104501.55.jpg\n",
      "2024-08-18 13:05:21,193 - INFO - Processed and saved image: C:\\Users\\hp\\Desktop\\ProcessedImages\\processed_images(Clache+size)\\1.3.6.1.4.1.25403.193662124755707.3324.20240319135309.130.jpg\n",
      "2024-08-18 13:05:21,196 - ERROR - Failed to load image: C:\\Users\\hp\\Desktop\\2914---1470\\ABDULKADÿR BÿLEN.jpg\n",
      "2024-08-18 13:05:21,259 - INFO - Processed and saved image: C:\\Users\\hp\\Desktop\\ProcessedImages\\processed_images(Clache+size)\\ABDULLAH TURHAN.jpg\n",
      "2024-08-18 13:05:21,261 - ERROR - Failed to load image: C:\\Users\\hp\\Desktop\\2914---1470\\ABDULLAH ÇELÿK(107913).jpg\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import logging\n",
    "# import numpy as np\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# # Set up logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# class EggShapeCropper(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, width, height, axes_ratio=(1, 1)):\n",
    "#         \"\"\"\n",
    "#         Initialize the EggShapeCropper with the desired width, height, and axes ratio.\n",
    "#         \"\"\"\n",
    "#         self.width = width\n",
    "#         self.height = height\n",
    "#         self.axes_ratio = axes_ratio  # Ratio to control the shape of the egg\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         \"\"\"\n",
    "#         Crop images to the specified egg shape, keeping the center part.\n",
    "#         \"\"\"\n",
    "#         cropped_images = []\n",
    "#         for img in X:\n",
    "#             # Ensure the image is large enough\n",
    "#             if img.shape[1] < self.width or img.shape[0] < self.height:\n",
    "#                 img = cv2.resize(img, (max(self.width, img.shape[1]), max(self.height, img.shape[0])), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "#             # Create an egg-shaped mask\n",
    "#             mask = np.zeros((self.height, self.width), dtype=np.uint8)\n",
    "#             center_x, center_y = self.width // 2, self.height // 2\n",
    "#             axes = (int(self.width // 2 * self.axes_ratio[0]), int(self.height // 2 * self.axes_ratio[1]))  # Adjust the axes here\n",
    "#             cv2.ellipse(mask, (center_x, center_y), axes, 0, 0, 360, 255, -1)\n",
    "            \n",
    "#             # Crop the image using the mask\n",
    "#             center_x_img, center_y_img = img.shape[1] // 2, img.shape[0] // 2\n",
    "#             half_width, half_height = self.width // 2, self.height // 2\n",
    "#             cropped_img = img[center_y_img - half_height:center_y_img + half_height, center_x_img - half_width:center_x_img + half_width]\n",
    "#             cropped_img = cv2.bitwise_and(cropped_img, cropped_img, mask=mask)\n",
    "            \n",
    "#             cropped_images.append(cropped_img)\n",
    "#         return cropped_images\n",
    "\n",
    "# class CLAHEEnhancer(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, clip_limit=2.0, tile_grid_size=(16, 16)):\n",
    "#         \"\"\"\n",
    "#         Initialize the CLAHEEnhancer with the desired clip limit and tile grid size.\n",
    "#         \"\"\"\n",
    "#         self.clip_limit = clip_limit\n",
    "#         self.tile_grid_size = tile_grid_size\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         \"\"\"\n",
    "#         Apply CLAHE to enhance the contrast of images.\n",
    "#         \"\"\"\n",
    "#         clahe = cv2.createCLAHE(clipLimit=self.clip_limit, tileGridSize=self.tile_grid_size)\n",
    "#         return [clahe.apply(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)) for img in X]\n",
    "\n",
    "# def preprocess_images(image_folder, output_dir):\n",
    "#     \"\"\"\n",
    "#     Preprocess images by cropping and applying CLAHE, then save the processed images.\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)\n",
    "#     processed_dir = os.path.join(output_dir, 'processed_images(Clache+size)')\n",
    "#     if not os.path.exists(processed_dir):\n",
    "#         os.makedirs(processed_dir)\n",
    "    \n",
    "#     # Create the pipeline\n",
    "#     pipeline = make_pipeline(\n",
    "#         EggShapeCropper(width=1930, height=1000, axes_ratio=(1, 1.2)),  # Adjust the axes_ratio to control the shape\n",
    "#         CLAHEEnhancer(clip_limit=2.0, tile_grid_size=(16, 16))\n",
    "#     )\n",
    "    \n",
    "#     # Get a list of image files in the folder\n",
    "#     image_files = [os.path.join(image_folder, file) for file in os.listdir(image_folder)]\n",
    "    \n",
    "#     for image_path in image_files:\n",
    "#         try:\n",
    "#             img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "#             if img is not None:\n",
    "#                 # Apply the pipeline\n",
    "#                 processed_img = pipeline.transform([img])[0]\n",
    "                \n",
    "#                 output_path = os.path.join(processed_dir, os.path.basename(image_path))\n",
    "#                 cv2.imwrite(output_path, processed_img)\n",
    "#                 logging.info(f\"Processed and saved image: {output_path}\")\n",
    "#             else:\n",
    "#                 logging.error(f\"Failed to load image: {image_path}\")\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "# # Folder containing your X-ray images (adjust this path)\n",
    "# image_folder_path = r\"C:\\Users\\hp\\Desktop\\2914---1470\"\n",
    "# # Directory where you want to save processed images\n",
    "# processed_images_dir = r\"C:\\Users\\hp\\Desktop\\ProcessedImages\"\n",
    "\n",
    "# # Call the function with the image folder path and processed directory\n",
    "# preprocess_images(image_folder_path, processed_images_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0182f-5501-480c-bfc9-652a3c37efc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
